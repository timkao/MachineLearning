{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMGXXgNF7k61"
   },
   "source": [
    "# __Text Classification using RNN__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario \n",
    "\n",
    "Imagine you are working for a news aggregator platform that collects articles from various sources. To improve the user experience, the platform wants to automatically categorize these articles into relevant topics. This categorization will help users discover articles of interest more efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective \n",
    "\n",
    "Your task is to develop a text classification model using Recurrent Neural Networks (RNNs) to classify these articles into predefined topics or categories. The platform has provided you with a dataset containing text articles and their corresponding labels. Your model should be able to analyze the content of these articles and assign them to the most appropriate category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions \n",
    "\n",
    "* Step 1: Importing the Libraries \n",
    "\n",
    "      -Import the necessary libraries using Python's import statements. \n",
    "\n",
    "      -These libraries include csv, tensorflow, numpy, Tokenizer and pad_sequences from TensorFlow's Keras module, and nltk for natural language processing. matplotlib is also imported for potential data visualization. \n",
    "\n",
    "* Step 2: Defining the Hyperparameters \n",
    "\n",
    "      -Set the value of vocab_size to 5000, representing the size of the vocabulary. \n",
    "\n",
    "      -Set the value of embedding_dim to 64, specifying the dimensionality of the word embeddings. \n",
    "\n",
    "      -Set the value of max_length to 200, indicating the maximum length of input sequences. \n",
    "\n",
    "      -Set the value of padding_type to post, specifying that padding should be added at the end of sequences. \n",
    "\n",
    "      -Set the value of trunc_type to post, indicating that truncation should be applied at the end of sequences. \n",
    "\n",
    "      -Set the value of oov_tok to OOV, representing the token to be used for out-of-vocabulary words. \n",
    "\n",
    "      -Set the value of training_portion to 0.8, representing the proportion of data to be used for training. \n",
    "\n",
    "* Step 3: Preprocessing the Data and Printing the Lengths of the Labels and Articles Lists. \n",
    "\n",
    "      -Define two empty lists, articles, and labels to store the articles and labels, respectively. \n",
    "\n",
    "      -Read the contents of the bbc-text.csv file using csv.reader and iterate through each row. \n",
    "\n",
    "      -Extract the label from the first column of each row and append it to the labels list. \n",
    "\n",
    "      -Process the article from the second column by removing stopwords and replacing consecutive spaces with a single space and then append it to the articles list. \n",
    "\n",
    "      -Print the lengths of the labels and articles lists to display the number of labels and processed articles, respectively. \n",
    "\n",
    "* Step 4: Splitting the Data into Training and Validation Sets \n",
    "\n",
    "      -Calculate the train_size by multiplying the length of the articles list with training_portion and converting it to an integer. \n",
    "\n",
    "      -Create train_articles by slicing the articles list from index 0 to train_size. \n",
    "\n",
    "      -Create train_labels by slicing the labels list from index 0 to train_size. \n",
    "\n",
    "      -Create validation_articles by slicing the articles list from train_size onward. \n",
    "\n",
    "      -Create validation_labels by slicing the labels list from train_size onward. \n",
    "\n",
    "      -Print the train_size to display the calculated value. The lengths of train_articles, train_labels, validation_articles, and validation_labels represent the number of items in each list. \n",
    "\n",
    "\n",
    "* Step 5: Initializing a Tokenizer and Fitting It on the Training Articles \n",
    "\n",
    "      -Initialize a Tokenizer object named tokenizer with the specified parameters: num_words representing the vocabulary size and oov_token representing the out-of-vocabulary token. \n",
    "\n",
    "      -Fit the tokenizer on the training articles (train_articles) using the fit_on_texts method. \n",
    "\n",
    "      -This step updates the tokenizer's internal word index based on the words in the training articles. \n",
    "\n",
    "      -Assign the word index obtained from the tokenizer to the variable word_index. \n",
    "\n",
    "      -Extract the first 10 items from the word_index dictionary. \n",
    "\n",
    "      -Print the resulting dictionary. \n",
    "\n",
    "* Step 6: Converting the Training Articles into Sequences Using the Tokenizer \n",
    "\n",
    "      -Convert the training articles (train_articles) into sequences using the texts_to_sequences method of the tokenizer object and assign the result to train_sequences. \n",
    "\n",
    "      -Print the sequence representation of the 11th training article (index 10) by accessing train_sequences[10]. \n",
    "\n",
    "* Step 7: Padding the Sequence \n",
    "\n",
    "      -Pad the sequences in train_sequences using the pad_sequences function . \n",
    "\n",
    "      -Set the maximum length of the padded sequences to max_length . \n",
    "\n",
    "      -Specify the padding type as padding_type and the truncation type as trunc_type . \n",
    "\n",
    "      -Assign the padded sequences to the variable train_padded. \n",
    "\n",
    "* Step 8: Printing the Length of Validation Sequences and the Shape of Validation Padded \n",
    "\n",
    "      -Convert the validation articles into sequences using the tokenizer and pad the sequences to a maximum length. Assign the result to validation_padded. \n",
    "\n",
    "      -Print the length of validation_sequences and the shape of validation_padded. \n",
    "\n",
    "      -Create a tokenizer for the labels and fit it on the labels list. \n",
    "\n",
    "      -Convert the training and validation labels into sequences using the label tokenizer and store the results in training_label_seq and validation_label_seq as NumPy arrays. \n",
    "\n",
    "* Step 9: Training the Model \n",
    "\n",
    "      -Create a sequential model using tf.keras.Sequential(). \n",
    "\n",
    "      -Add an embedding layer to the model with the specified vocabulary size (vocab_size) and embedding dimension (embedding_dim). \n",
    "\n",
    "      -Add a bidirectional LSTM layer to the model with the same embedding dimension. \n",
    "\n",
    "      -Add a dense layer to the model with the embedding dimension as the number of units and relu activation function. \n",
    "\n",
    "      -Add a dense layer with 6 units and the softmax activation function to the model. \n",
    "\n",
    "      -Print a summary of the model's architecture using model.summary(). \n",
    "\n",
    "* Step 10: Compiling the Model \n",
    "\n",
    "      -Compile the model using model.compile() with the loss function set to sparse_categorical_crossentropy, the optimizer set to adam, and the metrics set to accuracy. \n",
    "\n",
    "      -Set the number of epochs to 10. \n",
    "\n",
    "      -Train the model using model.fit() with the training padded sequences (train_padded) and training label sequences (training_label_seq). \n",
    "\n",
    "      -Specify the number of epochs as num_epochs, the validation data as the validation padded sequences (validation_padded) and validation label sequences (validation_label_seq), and verbose mode as 2. \n",
    "\n",
    "* Step 11: Plotting the Graph \n",
    "\n",
    "      -Define a function named plot_graphs that takes history and string as inputs. Inside the function, plot the training and validation values of the given metric (string) from the history object using plt.plot(). \n",
    "\n",
    "      -Set the x-axis label as Epochs and the y-axis label as the given metric (string). \n",
    "\n",
    "      -Call the plot_graphs function twice, first with history and accuracy as arguments, and then with history and loss as arguments. \n",
    "\n",
    "      -Display the generated plots showing the training and validation values of the accuracy and loss metrics over the epochs. \n",
    "\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RME2Qywv_p7Z",
    "outputId": "0c10d43c-5e5c-4adf-c70d-146e2a933598"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chentingkao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKxl5ljN-IKH"
   },
   "source": [
    "### Step 1: Importing the libraries\n",
    "- Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qLg1HxV27k64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 16:43:34.274861: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# In natural language processing (NLP), stopwords are common words that are usually removed from text\n",
    "# before processing. These words typically do not contain significant meaning and are often filtered\n",
    "# out to reduce noise and improve computational efficiency. Examples of stopwords in English include\n",
    "# \"and,\" \"is,\" \"in,\" \"the,\" \"of,\" and \"to.\"\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cvQu2uW_AF0"
   },
   "source": [
    "### Step 2: Defining the Hyperparameter\n",
    "- Set the value of __vocab_size__ to __5000__, representing the size of the vocabulary\n",
    "- Set the value of __embedding_dim__ to __64__, specifying the dimensionality of the word embeddings\n",
    "- Set the value of __max_length__ to __200__, indicating the maximum length of input sequences\n",
    "- Set the value of __padding_type__ to __post__, specifying that padding should be added at the end of sequences\n",
    "- Set the value of __trunc_type__ to __post__, indicating that truncation should be applied at the end of sequences\n",
    "- Set the value of __oov_tok__ to __OOV__, representing the token to be used for out-of-vocabulary words\n",
    "- Set the value of __training_portion__ to __0.8__, representing the proportion of data to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BecOwkf37k66"
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5682GVs7k66"
   },
   "source": [
    "### Step 3: Preprocessing the Data and Printing the Lengths of the Labels and Articles Lists.\n",
    "\n",
    "- Define two empty lists, articles, and labels to store the articles and labels, respectively\n",
    "- Read the contents of the **bbc-text.csv** file using csv.reader and iterate through each row\n",
    "- Extract the label from the first column of each row and append it to the labels list\n",
    "- Process the article from the second column by removing stopwords and replacing consecutive spaces with a single space and then append it to the articles list\n",
    "- Print the lengths of the labels and articles lists to display the number of labels and processed articles, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YOrfsrUe7k67",
    "outputId": "0a4c62c7-b3d9-4989-b984-dd18a5cb3f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "labels = []\n",
    "\n",
    "with open(\"/Users/chentingkao/PracticeData/bbc-text.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    # reader here should be an iterator.\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        article = row[1]\n",
    "        for word in STOPWORDS:\n",
    "            token = ' ' + word + ' '\n",
    "            article = article.replace(token, ' ')\n",
    "            # this line is weird.\n",
    "            article = article.replace(' ', ' ')\n",
    "        articles.append(article)\n",
    "print(len(labels))\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtk-qqt67k67"
   },
   "source": [
    "__Observations:__\n",
    "- There are only **2,225** articles in the data.\n",
    "- Then, we split into a training set and validation set, according to the parameter we set earlier, 80% for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C72gvCwGSa0k"
   },
   "source": [
    "### Step 4: Splitting the Data into Training and Validation Sets\n",
    "- Calculate the **train_size** by multiplying the length of the articles list with __training_portion__ and converting it to an integer.\n",
    "- Create **train_articles** by slicing the articles list from index **0** to **train_size**.\n",
    "- Create **train_labels** by slicing the labels list from index** 0 **to **train_size**.\n",
    "- Create **validation_articles** by slicing the articles list from **train_size** onward.\n",
    "- Create **validation_labels** by slicing the labels list from **train_size** onward.\n",
    "- Print the **train_size** to display the calculated value.\n",
    "\n",
    "- The lengths of **train_articles**, **train_labels**, **validation_articles**, and **validation_labels** represent the number of items in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EKMT9Fb37k68",
    "outputId": "f94cdaff-aa34-4b89-9fbb-b0ac8733c099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n",
      "1780\n",
      "1780\n",
      "445\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(articles) * training_portion)\n",
    "\n",
    "train_articles = articles[0: train_size]\n",
    "train_labels = labels[0: train_size]\n",
    "\n",
    "validation_articles = articles[train_size:]\n",
    "validation_labels = labels[train_size:]\n",
    "\n",
    "print(train_size)\n",
    "print(len(train_articles))\n",
    "print(len(train_labels))\n",
    "print(len(validation_articles))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx4Pb61WT2F3"
   },
   "source": [
    "__Observations:__\n",
    "- The value of **train_size** is calculated based on the proportion of training data.\n",
    "- The lengths of **train_articles**, **train_labels**, **validation_articles**, and **validation_labels** representing the number of items in each list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSR2G2lrWrue"
   },
   "source": [
    "### Step 5: Initializing a Tokenizer and Fitting It on the Training Articles\n",
    "\n",
    "- Initialize a **Tokenizer** object named tokenizer with the specified parameters: **num_words** representing the vocabulary size and **oov_token** representing the out-of-vocabulary token.\n",
    "- Fit the tokenizer on the training articles **(train_articles)** using the **fit_on_texts** method.\n",
    "- This step updates the tokenizer's internal word index based on the words in the training articles.\n",
    "- Assign the word index obtained from the tokenizer to the variable **word_index**.\n",
    "- Extract the first 10 items from the **word_index** dictionary.\n",
    "- Print the resulting dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2JrnZlTL7k68"
   },
   "outputs": [],
   "source": [
    "# Out-of-Vocabulary Token\n",
    "# This defines a token that will be used to represent words that are not in the tokenizer's vocabulary.\n",
    "# When the tokenizer encounters a word in the input text that it has not seen before (i.e., it is \"out-of-vocabulary\"),\n",
    "# it will replace that word with the <OOV> token.\n",
    "# This is useful to handle words that appear in the test data but were not present in the training data,\n",
    "# ensuring that the model can still process the input text without errors.\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# This specifies the maximum number of words to keep in the tokenizer's vocabulary.\n",
    "# The tokenizer will only keep the top 5000 most frequent words from the training data and discard the rest.\n",
    "# Limiting the vocabulary size helps manage the memory and computational requirements, especially\n",
    "# when working with large datasets.\n",
    "vocab_size = 5000\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_articles)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7lhT9_-f7k68",
    "outputId": "94612377-29ce-4be1-a344-1314df623319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'said': 2,\n",
       " 'mr': 3,\n",
       " 'would': 4,\n",
       " 'year': 5,\n",
       " 'also': 6,\n",
       " 'people': 7,\n",
       " 'new': 8,\n",
       " 'us': 9,\n",
       " 'one': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The <OOV> token is assigned the index 1.\n",
    "# The rest of the words are assigned indices based on their frequency in the training data.\n",
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ_XTmT_eU7b"
   },
   "source": [
    "__Observations:__\n",
    "- The code prints a dictionary containing the first 10 items from the word_index dictionary.\n",
    "- These items represent a subset of the word-to-index mappings generated by the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTDip0vPe30D"
   },
   "source": [
    "### Step 6: Converting the Training Articles into Sequences Using the Tokenizer\n",
    "- Convert the training articles **(train_articles)** into sequences using the **texts_to_sequences** method of the tokenizer object and assign the result to **train_sequences**\n",
    "- Print the sequence representation of the 11th training article (index 10) by accessing **train_sequences[10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qaNkkgzP7k69",
    "outputId": "67041ae9-3d47-4062-a77c-d431ccd9b13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2431, 1, 225, 4996, 22, 641, 587, 225, 4996, 1, 1, 1662, 1, 1, 2431, 22, 565, 1, 1, 140, 278, 1, 140, 278, 796, 822, 662, 2307, 1, 1145, 1693, 1, 1720, 4997, 1, 1, 1, 1, 1, 4738, 1, 1, 122, 4514, 1, 2, 2874, 1505, 352, 4739, 1, 52, 341, 1, 352, 2171, 3962, 41, 22, 3796, 1, 1, 1, 1, 543, 1, 1, 1, 835, 631, 2366, 347, 4740, 1, 365, 22, 1, 787, 2367, 1, 4302, 138, 10, 1, 3664, 682, 3532, 1, 22, 1, 414, 822, 662, 1, 90, 13, 633, 1, 225, 4996, 1, 599, 1, 1693, 1021, 1, 4998, 807, 1864, 117, 1, 1, 1, 2974, 22, 1, 99, 278, 1, 1607, 4999, 543, 493, 1, 1443, 4741, 779, 1320, 1, 1861, 10, 33, 641, 319, 1, 62, 479, 565, 301, 1506, 22, 480, 1, 1, 1665, 1, 797, 1, 3066, 1, 1364, 6, 1, 2431, 565, 22, 2971, 4735, 1, 1, 1, 1, 1, 850, 39, 1825, 675, 297, 26, 979, 1, 882, 22, 361, 22, 13, 301, 1506, 1342, 374, 20, 63, 883, 1096, 4303, 247]\n"
     ]
    }
   ],
   "source": [
    "# Machine learning models, particularly neural networks, require numerical input.\n",
    "# Words need to be converted into a numerical format that the model can process.\n",
    "# This numerical format is usually a sequence of integers, where each integer\n",
    "# represents a specific word in the vocabulary.\n",
    "\n",
    "# Converting text to sequences standardizes the input format, making it easier\n",
    "# to handle different lengths of text and manage padding or truncation.\n",
    "train_sequences  = tokenizer.texts_to_sequences(train_articles)\n",
    "\n",
    "print(train_sequences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__Jgr_cdfR_6"
   },
   "source": [
    "__Observation:__\n",
    "- The code prints the sequence representation of the 11th training article (index 10) in the **train_sequences** list.\n",
    "- The output is a list of integers, where each integer represents the index of a word in the tokenizer's word index vocabulary that corresponds to a word in the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E60-EoRMh58g"
   },
   "source": [
    "### Step 7: Padding the Sequence\n",
    "- Pad the sequences in **train_sequences** using the **pad_sequences** function\n",
    "- Set the maximum length of the padded sequences to **max_length**\n",
    "- Specify the padding type as **padding_type** and the truncation type as **trunc_type**\n",
    "- Assign the padded sequences to the variable **train_padded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "msiF0l767k69"
   },
   "outputs": [],
   "source": [
    "# This sets the maximum length for the sequences. All sequences will be padded or\n",
    "# truncated to ensure they have this exact length.\n",
    "max_length = 200\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iKwGCkXf7k69",
    "outputId": "dbee058a-2c8d-498e-ebf3-47525c709172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2431, 1, 225, 4996, 22, 641, 587, 225, 4996, 1, 1, 1662, 1, 1, 2431, 22, 565, 1, 1, 140, 278, 1, 140, 278, 796, 822, 662, 2307, 1, 1145, 1693, 1, 1720, 4997, 1, 1, 1, 1, 1, 4738, 1, 1, 122, 4514, 1, 2, 2874, 1505, 352, 4739, 1, 52, 341, 1, 352, 2171, 3962, 41, 22, 3796, 1, 1, 1, 1, 543, 1, 1, 1, 835, 631, 2366, 347, 4740, 1, 365, 22, 1, 787, 2367, 1, 4302, 138, 10, 1, 3664, 682, 3532, 1, 22, 1, 414, 822, 662, 1, 90, 13, 633, 1, 225, 4996, 1, 599, 1, 1693, 1021, 1, 4998, 807, 1864, 117, 1, 1, 1, 2974, 22, 1, 99, 278, 1, 1607, 4999, 543, 493, 1, 1443, 4741, 779, 1320, 1, 1861, 10, 33, 641, 319, 1, 62, 479, 565, 301, 1506, 22, 480, 1, 1, 1665, 1, 797, 1, 3066, 1, 1364, 6, 1, 2431, 565, 22, 2971, 4735, 1, 1, 1, 1, 1, 850, 39, 1825, 675, 297, 26, 979, 1, 882, 22, 361, 22, 13, 301, 1506, 1342, 374, 20, 63, 883, 1096, 4303, 247]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2TGYE5IjhOI"
   },
   "source": [
    "__Observations:__\n",
    "- The code prints the sequence representation of the 11th training article (index 10) in the **train_sequences** list.\n",
    "- The output is a list of integers, where each integer represents the index of a word in the tokenizer's word index vocabulary that corresponds to a word in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EQbLYMWl7k6-",
    "outputId": "fdaf57e7-3e98-4dcc-e4af-7b83c043e7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2431    1  225 4996   22  641  587  225 4996    1    1 1662    1    1\n",
      " 2431   22  565    1    1  140  278    1  140  278  796  822  662 2307\n",
      "    1 1145 1693    1 1720 4997    1    1    1    1    1 4738    1    1\n",
      "  122 4514    1    2 2874 1505  352 4739    1   52  341    1  352 2171\n",
      " 3962   41   22 3796    1    1    1    1  543    1    1    1  835  631\n",
      " 2366  347 4740    1  365   22    1  787 2367    1 4302  138   10    1\n",
      " 3664  682 3532    1   22    1  414  822  662    1   90   13  633    1\n",
      "  225 4996    1  599    1 1693 1021    1 4998  807 1864  117    1    1\n",
      "    1 2974   22    1   99  278    1 1607 4999  543  493    1 1443 4741\n",
      "  779 1320    1 1861   10   33  641  319    1   62  479  565  301 1506\n",
      "   22  480    1    1 1665    1  797    1 3066    1 1364    6    1 2431\n",
      "  565   22 2971 4735    1    1    1    1    1  850   39 1825  675  297\n",
      "   26  979    1  882   22  361   22   13  301 1506 1342  374   20   63\n",
      "  883 1096 4303  247    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_padded[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kR1yorJLkMpI"
   },
   "source": [
    "__Observation:__\n",
    "- The code prints the padded sequence representation of the 11th training article.\n",
    "- The output is a list of integers representing the word indices of the corresponding words in the article, after applying padding to ensure a consistent length (max_length) for all sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QD6M00flHAm"
   },
   "source": [
    "### Step 8: Printing the Length of Validation Sequences and the Shape of Validation Padded\n",
    "- Convert the validation articles into sequences using the tokenizer and pad the sequences to a maximum length. Assign the result to **validation_padded**\n",
    "- Print the length of **validation_sequences** and the shape of **validation_padded**\n",
    "- Create a tokenizer for the labels and fit it on the labels list\n",
    "- Convert the training and validation labels into sequences using the label tokenizer and store the results in **training_label_seq** and **validation_label_seq** as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fpgc3k9y7k6-",
    "outputId": "8cb8841f-058e-40ab-da03-b9778dcc6a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n",
      "(445, 200)\n"
     ]
    }
   ],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(len(validation_sequences))\n",
    "print(validation_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFFWDC12mo1e"
   },
   "source": [
    "__Observations:__\n",
    "- The length of **validation_sequences**, indicating the number of sequences in the validation set.\n",
    "- The shape of **validation_padded**, representing the dimensions of the padded validation sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8Q3nLd8W7k6-",
    "outputId": "caeaafd2-b5a9-473b-896a-3525b5ec7610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entertainment', 'politics', 'tech', 'sport', 'business'}\n",
      "{'entertainment', 'politics', 'tech', 'sport', 'business'}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))\n",
    "print(set(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0aPJkPCnkh3"
   },
   "source": [
    "__Observation:__\n",
    "- The output is a set containing the unique labels: 'business', 'tech', 'entertainment', 'politics', and 'sport'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WcsrX7dP7k6-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sport': 1, 'business': 2, 'politics': 3, 'tech': 4, 'entertainment': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels has only 5 words. hence, we do not need to specify num_words and oov_token\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
    "\n",
    "label_word_index = label_tokenizer.word_index\n",
    "dict(list(label_word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7VlgNsjpwKy"
   },
   "source": [
    "__Observations:__\n",
    "- The output of this code is the conversion of label sequences for the training and validation sets.\n",
    "- The **training_label_seq** and **validation_label_seq** are NumPy arrays containing the label sequences for the respective sets, based on the word index mapping generated by the **label_tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aefTdVG3ohC2"
   },
   "source": [
    "### Step 9: Training the Model\n",
    "- Create a sequential model using **tf.keras.Sequential()**\n",
    "- Add an embedding layer to the model with the specified vocabulary size **(vocab_size)** and embedding dimension **(embedding_dim)**\n",
    "- Add a bidirectional LSTM layer to the model with the same embedding dimension\n",
    "- Add a dense layer to the model with the embedding dimension as the number of units and **relu** activation function\n",
    "- Add a dense layer with 6 units and the **softmax** activation function to the model\n",
    "- Print a summary of the model's architecture using **model.summary()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "R2k0E1Cb7k6_",
    "outputId": "f95aedf0-2704-41e5-b694-46d42812ca61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Converts integer-encoded words into dense vectors of fixed size (embedding_dim).\n",
    "    # Parameters:\n",
    "    # vocab_size: The size of the vocabulary (number of unique tokens in the text).\n",
    "    # embedding_dim: The dimension of the embedding vectors.\n",
    "    # Output: A 3D tensor with shape (batch_size, sequence_length, embedding_dim).\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "\n",
    "    # Purpose: Processes the sequence data in both forward and backward directions using an LSTM\n",
    "    # (Long Short-Term Memory) layer, capturing context from both directions.\n",
    "    # Parameters:\n",
    "    # embedding_dim: The number of units in the LSTM cell (equal to the embedding dimension in this case).\n",
    "    # Output: A 2D tensor with shape (batch_size, 2 * embedding_dim) because it concatenates the\n",
    "    # forward and backward LSTM outputs.\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "\n",
    "    # why use 6? and why using 5 throws exception?\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RYZ5eRIqHSk"
   },
   "source": [
    "__Observation:__\n",
    "- The code outputs a summary of the model's architecture, including the number of parameters and the shape of each layer in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2es6RORPqq1M"
   },
   "source": [
    "### Step 10: Compiling the Model\n",
    "- Compile the model using **model.compile()** with the loss function set to **sparse_categorical_crossentropy**, the optimizer set to **adam**, and the metrics set to **accuracy**\n",
    "- Set the number of epochs to 10\n",
    "- Train the model using **model.fit()** with the training padded sequences **(train_padded)** and training label sequences **(training_label_seq)**\n",
    "- Specify the number of epochs as **num_epochs**, the validation data as the validation padded sequences **(validation_padded)** and validation label sequences **(validation_label_seq)**, and **verbose** mode as **2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oOBn4QRv7k6_",
    "outputId": "fa0bff37-a54e-482f-a868-cc10ffd5b163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 16:44:54.218092: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 5 which is outside the valid range of [0, 5).  Label values: 1 2 5 1 3 5 4 4 3 1 4 5 2 5 4 1 1 5 1 5 2 4 5 3 3 3 4 1 4 2 5 4\n",
      "2024-07-20 16:44:54.218155: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of 5 which is outside the valid range of [0, 5).  Label values: 1 2 5 1 3 5 4 4 3 1 4 5 2 5 4 1 1 5 1 5 2 4 5 3 3 3 4 1 4 2 5 4\n",
      "\t [[{{function_node __inference_one_step_on_data_4508}}{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/kc/_2nh1fbx6dd_bl9j35w1q0zw0000gn/T/ipykernel_81331/2445750279.py\", line 5, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 54, in train_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 357, in _compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 325, in compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 609, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 645, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 43, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 27, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 1853, in sparse_categorical_crossentropy\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 645, in sparse_categorical_crossentropy\n\nReceived a label value of 5 which is outside the valid range of [0, 5).  Label values: 1 2 5 1 3 5 4 4 3 1 4 5 2 5 4 1 1 5 1 5 2 4 5 3 3 3 4 1 4 2 5 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_4591]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_label_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_label_seq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/kc/_2nh1fbx6dd_bl9j35w1q0zw0000gn/T/ipykernel_81331/2445750279.py\", line 5, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 54, in train_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 357, in _compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 325, in compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 609, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 645, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 43, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 27, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 1853, in sparse_categorical_crossentropy\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 645, in sparse_categorical_crossentropy\n\nReceived a label value of 5 which is outside the valid range of [0, 5).  Label values: 1 2 5 1 3 5 4 4 3 1 4 5 2 5 4 1 1 5 1 5 2 4 5 3 3 3 4 1 4 2 5 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_4591]"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqnhF_pirkJL"
   },
   "source": [
    "__Observations:__\n",
    "- The code trains the model for the specified number of epochs and records the training and validation accuracy and loss metrics.\n",
    "- The output is an object named history that contains information about the training process, such as the loss and accuracy values at each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlqqXKGDtBhm"
   },
   "source": [
    "### Step 11: Plotting the Graph\n",
    "- Define a function named **plot_graphs** that takes history and string as inputs. Inside the function, plot the training and validation values of the given metric (string) from the history object using **plt.plot()**\n",
    "- Set the x-axis label as **Epochs** and the y-axis label as the given metric (string)\n",
    "- Call the **plot_graphs** function twice, first with **history** and **accuracy** as arguments, and then with **history** and **loss** as arguments\n",
    "- Display the generated plots showing the training and validation values of the accuracy and loss metrics over the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ovA5JGsp7k6_",
    "outputId": "ad5c088c-79a0-42aa-c6d9-9c70e1b4a618"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1aElEQVR4nO3dd3yUdbb48c/JpJNCC6GE3kNCjYgFBGxYVlQERAF1VVQUy7qW/eneu+t1r67uVdeua1uVFVgsiw1RQREVJUDovSe00BIgpJ/fH88AIYSQMpMnyZz36zWvzDxtzozynPl2UVWMMcYEriC3AzDGGOMuSwTGGBPgLBEYY0yAs0RgjDEBzhKBMcYEuGC3A6ispk2bart27dwOwxhj6pSFCxfuUdW4svbVuUTQrl07UlNT3Q7DGGPqFBHZcqp9fqsaEpG3RGS3iCwv55jBIpImIitE5Ht/xWKMMebU/NlG8A4w7FQ7RaQh8DJwhar2AEb6MRZjjDGn4LdEoKpzgX3lHHId8JGqbvUev9tfsRhjjDk1N9sIugAhIvIdEA38XVXfLetAEZkATABo06ZNjQVojKk9CgoKSE9PJzc31+1QarXw8HASEhIICQmp8DluJoJgoB9wPhAB/Cwi81V1bekDVfV14HWAlJQUmxzJmACUnp5OdHQ07dq1Q0TcDqdWUlX27t1Leno67du3r/B5bo4jSAe+UtXDqroHmAv0cjEeY0wtlpubS5MmTSwJlENEaNKkSaVLTW4mgv8A54pIsIhEAmcCq1yMxxhTy1kSOL2qfEf+7D76AfAz0FVE0kXkZhG5XURuB1DVVcBMYCnwK/CGqp6yq2l1bdpzmD9/uoKComJ/vYUxxtRJfmsjUNUxFTjmaeBpf8VQ0sbMQ7z942YSW8QwMqV1TbylMaaeiYqK4tChQ26H4XMBM9fQ0G7NSGwRw8vfbaCo2NqbjTHmqIBJBCLCpKGd2LTnMJ8t3e52OMaYOkxVeeCBB0hKSiI5OZmpU6cCsGPHDgYNGkTv3r1JSkrihx9+oKioiBtvvPHYsc8++6zL0Z+szs01VB0X92hO52ZRvDRnPb/p2ZKgIGt4MqYu+vOnK1i5Pdun10xsGcN//6ZHhY796KOPSEtLY8mSJezZs4czzjiDQYMG8a9//YuLL76YRx55hKKiInJyckhLSyMjI4Ply50m0AMHDvg0bl8ImBIBQFCQcNfQTqzddYhZK3e6HY4xpo6aN28eY8aMwePxEB8fz3nnnceCBQs444wzePvtt/nTn/7EsmXLiI6OpkOHDmzcuJFJkyYxc+ZMYmJi3A7/JAFVIgC4LLkFz369lhdmr+fiHs2tO5oxdVBFf7nXtEGDBjF37lw+//xzbrzxRn73u98xfvx4lixZwldffcWrr77KtGnTeOutt9wO9QQBVSIACPYEMXFwJ1Zsz+a7NZluh2OMqYMGDhzI1KlTKSoqIjMzk7lz59K/f3+2bNlCfHw8t956K7fccguLFi1iz549FBcXM2LECB5//HEWLVrkdvgnCbgSAcBVfVvx92/X8fzsdQzuGmelAmNMpVx11VX8/PPP9OrVCxHhqaeeonnz5vzzn//k6aefJiQkhKioKN59910yMjK46aabKC52xjA98cQTLkd/MlGtW10pU1JS1BcL07w3fwt//GQ5k285k3M6NfVBZMYYf1q1ahXdu3d3O4w6oazvSkQWqmpKWccHXNXQUSP7JdAsOowXZq9zOxRjjHFVwCaC8BAPt53Xkfkb97Fgc3nLJhhjTP0WsIkA4Lr+bWjSIJQXZq93OxRjjHFNQCeCiFAPtwzswNy1mSzZdsDtcIwxxhUBnQgAxg5oQ2xEiJUKjDEBK+ATQXR4CDed045vVu3y+ZB1Y4ypCwI+EQDcdHZ7osKCeek7KxUYYwKPJQIgNjKE8We15YtlO1i/+6Db4Rhj6oGoqKhT7tu8eTNJSUk1GE35/LlC2VsisltEyl11TETOEJFCEbnGX7FUxM3ntic82MPLcza4GYYxxtQ4f04x8Q7wIvDuqQ4QEQ/wV2CWH+OokCZRYVx/Zhve/mkz91zQmbZNGrgdkjHmVL58GHYu8+01myfDJU+ecvfDDz9M69atufPOOwH405/+RHBwMHPmzGH//v0UFBTw+OOPM3z48Eq9bW5uLnfccQepqakEBwfzzDPPMGTIEFasWMFNN91Efn4+xcXFfPjhh7Rs2ZJRo0aRnp5OUVERf/zjHxk9enS1Pjb4sUSgqnOB043UmgR8COz2VxyVMWFQBzxBwivfWanAGHOi0aNHM23atGOvp02bxg033MDHH3/MokWLmDNnDvfffz+VnbbnpZdeQkRYtmwZH3zwATfccAO5ubm8+uqr3HPPPaSlpZGamkpCQgIzZ86kZcuWLFmyhOXLlzNs2DCffDbXJp0TkVbAVcAQ4IzTHDsBmADQpk0bv8XULCaca89ozQe/bmXS+Z1p1TDCb+9ljKmGcn65+0ufPn3YvXs327dvJzMzk0aNGtG8eXPuu+8+5s6dS1BQEBkZGezatYvmzZtX+Lrz5s1j0qRJAHTr1o22bduydu1azjrrLP7yl7+Qnp7O1VdfTefOnUlOTub+++/noYce4vLLL2fgwIE++WxuNhY/BzykqsWnO1BVX1fVFFVNiYuL82tQt53XEVV47XsrFRhjTjRy5EimT5/O1KlTGT16NJMnTyYzM5OFCxeSlpZGfHw8ubm5Pnmv6667jhkzZhAREcGll17K7Nmz6dKlC4sWLSI5OZlHH32Uxx57zCfv5WYiSAGmiMhm4BrgZRG50sV4AGjVMIIRfROYsmAbu7N98x/UGFM/jB49milTpjB9+nRGjhxJVlYWzZo1IyQkhDlz5rBly5ZKX3PgwIFMnjwZgLVr17J161a6du3Kxo0b6dChA3fffTfDhw9n6dKlbN++ncjISMaOHcsDDzzgs7UNXEsEqtpeVdupajtgOjBRVT9xK56SJg7pSGFRMf/4YaPboRhjapEePXpw8OBBWrVqRYsWLbj++utJTU0lOTmZd999l27dulX6mhMnTqS4uJjk5GRGjx7NO++8Q1hYGNOmTSMpKYnevXuzfPlyxo8fz7Jly+jfvz+9e/fmz3/+M48++qhPPpff1iMQkQ+AwUBTYBfw30AIgKq+WurYd4DPVHX66a7rq/UITue+qWnMXL6TeQ8NoUlUmN/fzxhTPluPoOIqux6B3xqLVXVMJY690V9xVNWdQzrySVoGb/24iQcurnyWN8aYuiJwRhYfOQCLJ0PxadumAejULJpLk1rwz5+2kJVT4N/YjDH10rJly+jdu/cJjzPPPNPtsE4SOGsWr/0K/jMRGraB9hXrcnXnkE58vmwH73gHmRlj3KWqdWqN8eTkZNLS0mr0PatS3R84JYLuv4GwGFj8XoVPSWwZwwXd43nrx00cyiv0Y3DGmNMJDw9n7969VbrRBQpVZe/evYSHh1fqvMApEYRGQvI1kPYvuOQpiGhYodPuGtqJK1/6kffnb+H28zr6N0ZjzCklJCSQnp5OZmam26HUauHh4SQkJFTqnMBJBAB9xkHqW7B8OpxxS4VO6d26IQM7N+WNHzZyw1ntiAj1+DlIY0xZQkJCaN++vdth1EuBUzUE0LIPxCfBoopXDwHcfX5n9hzK54Nft/opMGOMcU9gJQIRp1SwI61SMxee0a4xZ7ZvzGtzN5BbUOS/+IwxxgWBlQgAeo4CT2ilSwWThnZmV3Ye0xem+ykwY4xxR+AlgsjG0O1yWDoVCio+l9A5nZrQp01DXvluAwVFFRuLYIwxdUHgJQKAvuMg9wCs+bzCp4gIk4Z2IuPAET5enOG/2IwxpoYFZiJoPxhi21S6emhI12b0aBnDy3PWU1RsfZmNMfVDYCaCoCDocz1s/A4OVLwn0NFSwea9OXy2dLv/4jPGmBoUmIkAoPd1zt/Fkyt12kWJzekSH8VLc9ZTbKUCY0w9ELiJoGEb6DAY0iZDccW7hAYFCXcO6cTaXYeYtXKn/+IzxpgaEriJAJxG46xtThVRJVzesyXtmzbghdnrbd4TY0ydF9iJoNvlENGoUhPRAXiChDsGd2TF9mzmrNntp+CMMaZmBHYiCA6DnqNh9eeQs69Sp17VpxWtGkbw/LdWKjDG1G1+SwQi8paI7BaR5afYf72ILBWRZSLyk4j08lcs5eozDorynQFmlRDiCeKOwR1J23aAnzbs9VNwxhjjf/4sEbwDDCtn/ybgPFVNBv4HeN2PsZxa8yRnMrpF70Elf9mPTEkgPiaM579d56fgjDHG//yWCFR1LnDK+hZV/UlV93tfzgcqN4G2L/UZB7tXwPbFlTotLNjDbYM68sumffy6qXJVS8YYU1vUljaCm4EvT7VTRCaISKqIpPplUYrkayA4otKNxgBj+rehaVQoL8y2UoExpm5yPRGIyBCcRPDQqY5R1ddVNUVVU+Li4nwfRHgsJA6HZdMhP6dSp0aEerhlYAd+WLeHtG0HfB+bMcb4mauJQER6Am8Aw1XV3RbXPmMhLxtWzaj0qWMHtCU2IoQXZ6/3Q2DGGONfriUCEWkDfASMU9W1bsVxTLtzoVH7Sk9EBxAVFsxvz2nPN6t2sXJ7th+CM8YY//Fn99EPgJ+BriKSLiI3i8jtInK795D/ApoAL4tImoik+iuWChFxSgVb5sHeDZU+/cZz2hEdFsxLc6xUYIypW/zZa2iMqrZQ1RBVTVDVN1X1VVV91bv/FlVtpKq9vY8Uf8VSYb2vAwmCxe9X+tTYiBDGn92WL5bvYP3ug34Izhhj/MP1xuJaJaYldLoQ0v4FRYWVPv3mczsQHuzhpTmVL1EYY4xbLBGU1nccHNoJ67+p9KmNG4QydkAb/pOWwZa9h/0QnDHG+J4lgtK6DIMGcVUaUwBw68AOBHuCeOU7KxUYY+oGSwSleUKg17WwdiYcqvzMos1iwhlzRms+XJROxoEjfgjQGGN8yxJBWfqMh+JCWDKlSqdPOK8jAK99b6UCY0ztZ4mgLHFdoPWZTvVQFaaYbtUwghF9E5iyYBu7s3P9EKAxxviOJYJT6TMO9qyFbb9W6fSJgztRVKy8PnejjwMzxhjfskRwKj2uhJAGsPjdKp3epkkkw3u1ZPIvW9l7KM+3sRljjA9ZIjiVsGhIugqWfwx5VRsgNnFIJ3ILi3hz3iYfB2eMMb5jiaA8fcZDwWFY8XGVTu/ULIpLk1vw7s9byMop8HFwxhjjG5YIytO6PzTtUqWJ6I66a0gnDuUV8s5Pm30XlzHG+JAlgvKIOI3G6b9C5poqXaJ7ixguTIznrR83cTDXSgXGmNrHEsHp9BoDQcGwqGqNxuCUCrKOFPD+/K0+DMwYY3zDEsHpRMU5004smQKF+VW6RK/WDRnUJY43ftjIkfwiHwdojDHVY4mgIvqOh5w9sO6rKl/i7qGd2Hs4n3/9aqUCY0ztYomgIjqeD9EtqtVonNKuMQM6NOb1uRvILbBSgTGm9vDnCmVvichuEVl+iv0iIs+LyHoRWSoiff0VS7V5gp1Fa9Z/Ddnbq3yZSUM7sys7j+kL030YnDHGVI8/SwTvAMPK2X8J0Nn7mAC84sdYqq/39aDFzqI1VXR2xyb0bdOQV77bQF6hlQqMMbWDP5eqnAvsK+eQ4cC76pgPNBSRFv6Kp9qadIS25zrLWBYXV+kSIsJ9F3Yh48ARJlsPImNMLeFmG0ErYFuJ1+nebScRkQkikioiqZmZmTUSXJn6joP9m2DLj1W+xMDOcZzbqSkvzF5Hto0rMMbUAnWisVhVX1fVFFVNiYuLcy+Q7ldAWEyVVy876uFLurE/p8DWKzDG1ApuJoIMoHWJ1wnebbVXaCQkXwMr/wNHDlT5MkmtYrmiV0venLeJXbZegTHGZW4mghnAeG/voQFAlqrucDGeiukzDgpzYfn0al3mgYu7UlSsPPfNWh8FZowxVePP7qMfAD8DXUUkXURuFpHbReR27yFfABuB9cA/gIn+isWnWvaB+KRqjSkAaN04krED2jJ1wTbW767aNNfGGOML/uw1NEZVW6hqiKomqOqbqvqqqr7q3a+qeqeqdlTVZFVN9VcsPnV0IrodabBzWbUuddeQTkSGBvPUzKpNaGeMMb5QJxqLa52eo8AT6nQlrYYmUWHcfl4HZq3cRerm8nraGmOM/1giqIrIxtDtclg6FQqrtwzlb89tT7PoMJ74cjWq6qMAjTGm4iwRVFXfcXBkP6z+rFqXiQwN5t4LurBwy35mrdzlo+CMMabiLBFUVfvBENu62o3GAKNSEugY14CnZq6msKhqo5aNMaaqLBFUVVCQM//Qxu/gQPWmiwj2BPHgsG5syDzMv21COmNMDbNEUB19rnf+Lp5c7UtdlBhPv7aNePbrteTkF1b7esYYU1GWCKqjYRvoMBjSJkNx9WYTFRH+cEk3dh/M4+0fN/skPGOMqQhLBNXVdxxkbXOqiKoppV1jLkyM59XvNrDvcNWWxTTGmMqyRFBd3S6HiEbVnojuqAcv7srh/EJemL3OJ9czxpjTsURQXcFh0HM0rP4ccqo/KKxzfDSjUlrz/vwtbNuX44MAjTGmfJYIfKHPOCjKdwaY+cC9F3TBEyT8bZZNPWGM8T9LBL7QPMmZjG7Re+CD0cHNY8P57Tnt+U/adpZnZPkgQGOMOTVLBL7SZxzsXgHbF/vkcrcP7kijyBD+OnO1T65njDGnYonAV5JGQHC4zxqNY8JDuGtoZ35Yt4cf1rm4PKcxpt6zROArEQ0hcTgsmw75vmnkHTugDQmNInjyy9UUF9uEdMYY/7BE4Et9xkFeNqya4ZPLhQV7+P1FXVmxPZtPl273yTWNMaa0CiUCEblHRGK8y0q+KSKLROQifwdX57Q7Fxq198lEdEdd0aslPVrG8PRXa8grrN7oZWOMKUtFSwS/VdVs4CKgETAOePJ0J4nIMBFZIyLrReThMva3EZE5IrJYRJaKyKWVir62EYE+Y2HLPNi7wSeXDAoSHr6kG+n7j/D+/OpNbmeMMWWpaCIQ799LgfdUdUWJbWWfIOIBXgIuARKBMSKSWOqwR4FpqtoHuBZ4uaKB11q9rwMJqvbqZSUN7BzHuZ2a8uLsdWTnFvjsusYYAxVPBAtFZBZOIvhKRKKB002c3x9Yr6obVTUfmAIML3WMAjHe57FA3a8Ij2kJnS6EtH9Bke9mEX34km7szyngte99U9IwxpijKpoIbgYeBs5Q1RwgBLjpNOe0AraVeJ3u3VbSn4CxIpIOfAFMKutCIjJBRFJFJDUzsw50pew7Dg7thPXf+OySSa1iGd67JW/O28TOrFyfXdcYYyqaCM4C1qjqAREZi1Ol44shr2OAd1Q1AW+1k4icFJOqvq6qKaqaEhcX54O39bMuw6BBnM/GFBz1+4u6UlSsPPfNWp9e1xgT2CqaCF4BckSkF3A/sAF49zTnZACtS7xO8G4r6WZgGoCq/gyEA00rGFPt5QmBXtfC2plwaLfPLtu6cSRjB7RlWuo21u8+6LPrGmMCW0UTQaGqKk4d/4uq+hIQfZpzFgCdRaS9iITiNAaX7mC/FTgfQES64ySCOlD3UwF9xkFxISyZ4tPLThramcjQYP460yakM8b4RkUTwUER+QNOt9HPvdU3IeWdoKqFwF3AV8AqnN5BK0TkMRG5wnvY/cCtIrIE+AC40Ztw6r64rpDQ36ke8uFHatwglNvP68DXK3eRurn6014bY0xFE8FoIA9nPMFOnGqep093kqp+oapdVLWjqv7Fu+2/VHWG9/lKVT1HVXupam9VnVXFz1E79R0He9bCtl99etnfntueZtFhPPHlaupL3jTGuKdCicB7858MxIrI5UCuqp6ujcD0uApCGsBi335VkaHB3HdhFxZu2c+slbt8em1jTOCp6BQTo4BfgZHAKOAXEbnGn4HVC2HRkHQVLP8Y8nzbuDuyXwId4xrw1MzVFBadbkiHMcacWkWrhh7BGUNwg6qOxxks9kf/hVWP9BkPBYdhxcc+vWywJ4gHh3VjQ+Zh/r0w3afXNsYEloomgiBVLdkPcm8lzg1srftD0y4+nYjuqIsS4+nXthHPfr2WnHzfjWI2xgSWit7MZ4rIVyJyo4jcCHyOMxLYnI6I05U0/VfI9G2XTxHhD5d0Y/fBPN6at8mn1zbGBI6KNhY/ALwO9PQ+XlfVh/wZWL3SawwEBcMi37evp7RrzIWJ8bz6/Ub2Hc73+fWNMfVfhat3VPVDVf2d9+HbCu/6LirOmXZiyRQo8v3soQ8N60pOfiEvzF7n82sbY+q/chOBiBwUkewyHgdFJLumgqwX+o6HnD3OtBM+1qlZNKNSWvP+/C1s3eubZTKNMYGj3ESgqtGqGlPGI1pVY8o715TS8XyIau6XRmOA+y7sgidI+L+vbeoJY0zlWM+fmuIJdhatWf81ZPt+2YX4mHBuPrc9/0nbzvIMX0wMa4wJFJYIalKfsaDFzqI1fnDbeR1pFBnCk1+u9sv1jTH1kyWCmtSkI7Q9Fxa8AWtmQrFvRwTHhIdw19DOzFu/h7lr68ckrsYY/7NEUNPO/yOIBz4YDS+fCQv/CQW+W3Fs7IA2JDSK4MkvV1NcbBPSGWNOzxJBTWszAO5Jg6vfgOAw+PRueC4Jvn8acqo/rXRYsIffX9SVlTuymbGk7i8BbYzxP0sEbvCEQM+RcNsPMH4GtOgNcx6HZxLh89/Dvo3VuvwVvVrSo2UMf5u1hrzCIt/EbIyptywRuEkEOpwHY6fDHT9D0ghY+A483xemjoNtC6p02aAg4eFLupG+/wjvz9/q25iNMfWOXxOBiAwTkTUisl5EHj7FMaNEZKWIrBAR/3SnqQviE+HKl+DeZXDufbDpe3jzAnjzYlj1GRRX7pf9wM5xnNupKS/OXkd2ru9HMxtj6g+/JQIR8QAvAZcAicAYEUksdUxn4A/AOaraA7jXX/HUGTEt4IL/hvtWwrC/wsHtMPV6ePEMWPAm5Fd85PDDl3Rjf04Br363wY8BG2PqOn+WCPoD61V1o6rmA1OA4aWOuRV4SVX3A5Sa6jqwhUXBgNth0mK45m0Ij4HPf+c0LM95Ag6dvntoUqtYhvduyVs/bmJnlu96Jhlj6hd/JoJWwLYSr9O920rqAnQRkR9FZL6IDCvrQiIyQURSRSQ1MzPA+sd7giHparh1Dtz4BST0h++fdBLCp/fCnvInmvv9RV0pKlae+2ZtzcRrjKlz3G4sDgY6A4OBMcA/RKRh6YNU9XVVTVHVlLi4uJqNsLYQgXbnwHVT4M4F0HO0M0L5xTPgg+tgy89QxkL2rRtHMnZAW6albmPdLt8ul2mMqR/8mQgygNYlXid4t5WUDsxQ1QJV3QSsxUkMpjxxXeCK5+G+5TDoAdj6E7w9DN64AFZ8clLD8qShnYkMDeapr2xCOmPMyfyZCBYAnUWkvYiEAtcCM0od8wlOaQARaYpTVVS9TvSBJKoZDH3EaVi+9G+Qsxf+fQM83wd+eR3yDwPQuEEot5/Xga9X7iJ1c/UHrRlj6he/JQJVLQTuAr4CVgHTVHWFiDwmIld4D/sK2CsiK4E5wAOqutdfMdVboZHQ/1aYtBBGvQdR8fDlA84AtW//Bw7u4rfntqdZdBj/+8UqtIwqJGNM4JK6dlNISUnR1NRUt8Oo/bb+Aj+/4IxB8IRAz9F8HjWCO7/O4bVx/bi4R3O3IzTG1CARWaiqKWXtC67pYEwNaXOm89i7Aea/DIsnc1nhezRpkMK0z67k/K4TCQ72uB2lMaYWsBJBoDi8F1LfJO+nVwjL28e+mO40vuQR6Ha50yPJGFOvlVcicLv7qKkpDZrAeQ8Sev8KXom+m+zsLJg6FiZfU+1J7owxdZslggAjoZGcMeI+zs/9K3Pa3++0Jbx8Fnz/FBTmuR2eMcYFlggCUEq7xgxLTuCmVf14PvFfFHe5BOb8xUkIG+a4HZ4xpoZZIghQz4zuxdgBbXhm/kGuO3AbB0ZMBRTeuxKm/xYO7nQ7RGNMDbFEEKDCgj08fmUyz4zqRdq2A1z8aTCLLvsCBv/B6XL64hnwy2uVnv7aGFP3WCIIcFf3TeDjiecQHuJh1JuLeTtkNDrxZ0hIgS8fhH8MgYyFbodpjPEjSwSG7i1imHHXuQzu2ow/f7qSe2Zlc3jkNGf664O74B/nw2e/gyP73Q7VGOMHlggMALERIbw+rh8PXNyVz5Zu56pXfmJj/EVw1wIYcAcsfNupLloypcxZTo0xdZclAnNMUJBw55BOvPvbM9lzKJ8rXvyRmesPw7AnYML30LAtfHwb/PM3kGkzmRpTX1giMCc5t3NTPpt0Lh2bRXH7+4t44otVFDZLgpu/hsufg53L4JVz4Js/V2rpTGNM7WSJwJSpZcMIpt02gLED2vDa3I2MffMXMg8XQMpNcFcqJI+Eec/Ay2fCmpluh2uMqQZLBOaUSncxvfyFH1i4ZR9ExcFVrzhLZ4ZEwgejYcr1cGDb6S9qjKl1bNI5UyErt2dzx+SFZOw/wqOXdeeGs9shIlCYD/NfcqaoABj8MAyY6Ex9bUxl5GbBrpWwaznsWuE8IhrBb56DmJZuR1fnlTfpnCUCU2FZRwq4f1oa36zazRW9WvLkiGQiQ70zmR/YCl8+DGs+h7jucPkz0PZsdwM2tVNRIezbcOINf9cKyCpRogxvCPE9YHsahDaAUe9C27PcirhesERgfKa4WHnl+w3836w1dGoWxatj+9EhLur4AWu+hC8ehKyt0Pt6uPAxaNDUvYCNuw5lOjf83Su9N/zlsHs1FHknOAwKhqZdnJt+fA9o5v0b09KZHn33aphyHRzYAsOehDNusWnTq8i1RCAiw4C/Ax7gDVV98hTHjQCmA2eoarl3eUsEtcO8dXu4e8pi8guL+dvIngxLanF8Z/5hmPs0/PQChEbBhX+GPuMhyJqk6q3CPKdL8dGb/dFf+Yd3Hz8mKv74DT8+yfnbtAsEh5V/7dws+Og2WPsl9LrOKW2GRPj389RDriQCEfEAa4ELgXScxezHqOrKUsdFA58DocBdlgjqju0HjnDH5EUs2XaA2wZ14IGLuxLsKXGz370aPr8ftsyDhP7OP+Dmye4FbKpPFbIzSt3wV8KetaDeeamCwyGu2/Gb/dFHdUqGxcUw9yn47glo0QtGvw8N2/jmMwUItxLBWcCfVPVi7+s/AKjqE6WOew74GngA+L0lgrolr7CI//lsJe/P38qADo15YUxf4qJL/MJTdUYjz3rUmaLizNthyB8gLNq9oE3F5B2CzNWl6vKXO7/Qj2rY5nh1ztFf+o07gMdPq+Cu+RI+muB0Rrjmbehwnn/epx5yKxFcAwxT1Vu8r8cBZ6rqXSWO6Qs8oqojROQ7TpEIRGQCMAGgTZs2/bZs2eKXmE3VfbQonf/38TJiI0J4+fq+9Gvb+MQDcvbBt4/BwncgurkzWjnxSv/U9xYVQG425GU5N61jj+zjz/OyT9yXfwhapUDPUdD6zMCsh1Z1JhhcOg3Wfw37NgHe+0No1Im/7uOToFl3CI+t+Tj3rIep1zulkAsfg7PuCsz/XpVUKxOBiAQBs4EbVXVzeYmgJCsR1F6n7GJaUnoqfHavMzq54/lw2d+cX5AlFeSeeJOuzA09NxsKDp8mUoHwGOcmFh4LYbHOL8yt86HwiPMrN3kkJI+CZt18+RXVTnvWw7JpsOzfzrKlnjDodD607HP8xh/bpna18eQdhE8mwqoZkDQCrnjB6V1kTqlWVg2JSCywATjkPaU5sA+4orxkYImgdiu3i+lRRYWw4A2Y/TgU5Ts3mpI39KL88t8kKPj4TTw8FsJiTnxd+lF6f2hU2Te1vIPOWgzLpsHG70CLoXlPp5SQNKJ+9WU/uAuWf+h81u2LAYH2A53kl3iFO7/0K0sV5j3rlDSbJcK175/8o8Ic41YiCMZpLD4fyMBpLL5OVVec4vjvsBJBvXDaLqZHZe9wlsg8uKOMm3mM05e8rBt5SIT/qwIO7oIVHznVJNsXUSdvlKXlZsPqz5zPtOn7+pPo1n/rrKqHwoi3oPMFbkdUK7nZffRS4Dmc7qNvqepfROQxIFVVZ5Q69jssEdQrJ3Yx7cWwpOZuh1Q1e9Y71SZLp8L+TU7VSZeLnRto54tO3/3RTYX5sP4b55f/mi+hMNeZRTZ5pBN/XFe3I/SNfZtg6jinMXvoozDwfms3KMUGlBnXZBw4wsT3F7IkPYvbzuvAAxeV6mJal5RsTF3xERzOdEoGiVc6N9U2Z9eOevTiYtg234lz5SdOb62IxpB0tVOiad2/ft4k83Pg07udpN3tcrjyFadkaQBLBMZleYVFPPbpSib/spWzOjTh+TF9TuxiWhcVFTrtCMumOe0KBYchJgGSRzg32+ZJNR/TrpXeRt8PnZHdwRHQ7TInSXUcGhjzP6nC/Fec7spNOsK1/4Kmnd2OqlawRGBqhQ8XOl1MG0aG8PL1/ejXtpHbIflG/mGn2mXpNKcaRoucxsvkkc6jYWv/vXdWOiyb7vwK3rUcxAMdhzjJqNtlEFZG20wg2PQD/PtGZ8Tz1a8530WAs0Rgao2V27O5/f2F7Mg6wqOXJTL+rLYndzGtyw7vgRUfO0kh/VdnW5uznV/licMhsnH551fEkf2w8j+w9N+w5UdAj4+B6HEVRDWr/nvUB1npMHWs0ytq0IMw+A+1o+rOJZYITK1Ssovp8N4teeLqMrqY1gf7Nnl/rU9zBj8FhTiNyz1HQpdhlZsvpyAX1n3lJJh1s5wutk06Ob/8k69xqkHMyQpynWlO0t53vvur/wERDd2OyhWWCEytU7KLadsmDfjbyF71p6qoNFXYscSpvlk2HQ7thNBopxtq8khoPwiCPCefV1wEm+c5iWTlp87Auqh4p6tn8khnwFd9Kk35iyqkvulMk96wNYyeDPGJbkdV4ywRmFrrpw17eODfS9mRdYRbB3Xgvgu6EB5Sxk2xvigugk1znaSwcgbkH4So5s7NvecoZ0K1nUudX/7LP3TGWIRGQ/ffOCWJdoP8N49Pfbd1Pkwb78yhNPxFpxdVALFEYGq1g7kF/O8Xq/jg1210bhbF/43qRc+Ehm6H5X8FR2DtTKeuf90sKC5wVuQ6st9bjXSh88u/6yU27bKvZO9wkkH6r3DOPTD0vwImsVoiMHXCd2t28/CHy8g8lMedgzty19DOhAYHSONezj6nAXjzPGdltx5X+aZh2ZysMB9mPgSpb0GHwc4spgHwXVsiMHVG1pEC/vzpCj5alEFiixj+b1QvurewQUHGDxa9B5//zqmau/Z9p1quHisvEQTIzy1TV8RGhPDMqN78Y3wKuw/mccWL83hx9joKi4rdDs3UN33HwU0znXEfb17krJsRoCwRmFrpwsR4vr5vEBf3aM7fZq1lxCs/sX73QbfDMvVNQj+Y8L0zDuPj2+DLh5z1LAKMJQJTazVqEMqL1/Xlpev6snVfDpc+P4/X526gqLhuVWeaWi4qDsZ/AgMmwi+vwrvD4dDu055Wn1giMLXeZT1bMOu+8xjcJY7//WI1o177mU17Trf4jDGV4AlxVs27+h+QsQheOw/SF7odVY2xRGDqhLjoMF4b149nR/di3a6DXPL3ubz94yaKrXRgfKnnKLh5ltOl9O1hsOhdtyOqEdZryNQ5O7NyefijpXy3JpMBHRrz9DW9aN040u2wTH2Ss89Z7GbjHOh3E1z0OEiQ07BcXOhM9V1c6H3t3abFJZ4f3V5U6pjS2wtLHVN6e/GJx7TqB+3OrdJHsu6jpt5RVaalbuN/PluFqvLIZYmM6d+6fk1gZ9xVXOQsg/njc25Hctw598CFj1XpVDdXKBsG/B1nhbI3VPXJUvt/B9wCFAKZwG9VdUt517REYEpK35/DQx8u5cf1exnUJY6/jkimRayNwjU+tGG2M4OpeJz1soM83ueeEs+Pbg8q5xjvceVuDyp1TLD3mt7nntAqryvh1prFHpw1iy8E0nHWLB6jqitLHDME+EVVc0TkDmCwqo4u77qWCExpxcXK5F+28L9frCbYI/zX5Ylc0y/BSgfGlODWgLL+wHpV3aiq+cAUYHjJA1R1jqrmeF/OBxL8GI+pp4KChHFntWPmvQPp3jyGB6Yv5dZ3U9mdnet2aMbUCf5MBK2AbSVep3u3ncrNwJdl7RCRCSKSKiKpmZmZPgzR1CdtmzRgyoQBPHpZd35Yt4eLnpvLf9IyqGvtYMbUtFrRfVRExgIpwNNl7VfV11U1RVVT4uLiajY4U6cEBQm3DOzA53cPpF2TBtwzJY2Jkxex91Ce26EZU2v5MxFkACUXa03wbjuBiFwAPAJcoar2r9X4RKdmUUy//SweHNaVb1ft5qJn5zJz+Q63wzKmVvJnIlgAdBaR9iISClwLzCh5gIj0AV7DSQKBNabb+F2wJ4iJgzvx6aRzaR4bzu3vL+LeKYs5kJPvdmjG1Cp+SwSqWgjcBXwFrAKmqeoKEXlMRK7wHvY0EAX8W0TSRGTGKS5nTJV1bR7NJ3eew70XdOazpTu46Nm5zF69y+2wjKk1bECZCSjLM7K4f9oS1uw6yMh+CfzxN4nEhFetX7YxdYmtR2CMV1KrWGZMOoeJgzvy4aJ0hj07lx/WWU80E9gsEZiAExbs4cFh3fjwjrMJD/Uw7s1feeTjZazdddAWwDEByaqGTEDLLSjib1+t4c0fN6EKocFBdI2PpnuLaBJbxNC9RQzdWsQQG2HVR6Zus0nnjDmNzXsOs3jbflbtOMiqHdms3J7N3sPHexclNIqge4uYY8khsUUMrRtH2DQWps4oLxEE13QwxtRG7Zo2oF3TBlzVx3mtqmQezGPFjuxjiWHVjmy+XbWLo0sgRIcF061EyaF7ixi6No8mPMTj3gcxpgosERhTBhGhWUw4zWLCGdK12bHtR/KLWLPLKTUcTRAfLsrgUJ4zaW6QQIe4qBLJIZrEljE0iw5366MYc1qWCIyphIhQD71bN6R364bHthUXK9v25ziJYcdBVm7PZuGW/cxYsv3YMU2jQo9VKSW2dJJEh6YNCPZYfw3jPksExlRTUJDQtkkD2jZpwLCkFse2Z+UUsGpniaqlndm8/eNm8r09k6xh2tQW1lhsTA0qKCpmY+Zhb+khu8yG6UaRIbRuHElCowhaN4okoeTzRhHWBmGqxBqLjaklQjxBdG0eTdfm0VzZx5mV/WjD9Mod2azeeZBt+3LYtv8Iq3cc5JtVu8kvPHFsQ7PoMCcxNI6kdaNIWjeOIKGR87xFw3BCrLrJVJIlAmNcVrJhenCJhmlw2h8yD+V5k0MO6fuOsG1/Dtv2HWHhlv18tnQHRcXHS/VBAi1iI05IFMeeN44gPjqcoKDa1+W1qFjJyS8kJ7+Iw3nO35z8IgqKignxBBHiEe/f489Dg4MIDhJCgoMI9e7z1MLPVhdYIjCmFgsKEuJjwomPCSelXeOT9hcWFbMjK/dYkkjf75Qmtu3L4Yd1mezKPnFm9xCP0KphhLfqqUSS8P5t0iC03LERxcXKkYIiDucXkpPn/D2SX8Th/CJyjt3AC094fdi77di+vJKvnRt/XqFvRnSLOKWuUE8QwUcThjd5BHuTRah3e8n9Jx5b4nWwc258TDhJrWLp3jyGiND6VzVnicCYOizYE+T9tR8JHU/en1tQxPYDR44lh/T9R7xJI4evtu9k3+ETp+SOCPGQ0CiCuOgwcguKjt2sj97AjxQUVSq+yFAPkaHBNAhz/kaGeogOD6Z5TDiRYR4iQz00CA0+dkzEsdceGoQFExwkFBYr+UXFFBQWU1CkFBYXk1/G84KiYgqLiskv47nz2nudYw/lUF7hyfsKy7iut9QVJNC5WTQ9WsWQ3CqWpFaxJLaIoUFY3b6V1u3ojTHlCg/x0CEuig5xUWXuP5xX6CSHfTknlCb2Hs4nMjSYJlFhNAj1EBkWTINQDxGhwSe8LutGf/R1eLCnVlZDVZaqsjM7l2XpWSzfns3yjCzmrdvDR4ucdbZEoEPTBscSQ1KrWBJbxtSpWW2t15AxxlTB7uxclm/PYll6Nsu3Z7E8I4sdWbnH9rdv2oAeLY+XHJJaxhIb6V5ysF5DxhjjY81iwhkaE87QbvHHtu05lMfyjCzvI5vFWw/w2dLjS6S2bhxBcqtYerSMPZYgGjcIdSP8E/g1EYjIMODvgAd4Q1WfLLU/DHgX6AfsBUar6mZ/xmSMMf7SNCqMwV2bndD7a//hfG+JwalWWr49iy+W7Ty2v1XDiBNLDq1iiYsOq9G4/ZYIRMQDvARcCKQDC0RkhqquLHHYzcB+Ve0kItcCfwVG+ysmY4ypaY0ahDKwcxwDO8cd25Z1pIAV3uqkZRnZrMjIYtbK48unxseEnVRyiI8J89tst/4sEfQH1qvqRgARmQIMB0omguHAn7zPpwMviohoXWu4MMaYSoiNCOHsjk05u2PTY9sO5hawcns2yzKyWOH9++3q3Ry9GzaNCuO2QR24dVAHn8fjz0TQCthW4nU6cOapjlHVQhHJApoAe/wYlzHG1DrR4SGc2aEJZ3Zocmzb4bxCVu3IPlZyaBbjnyqjOtFYLCITgAkAbdq0cTkaY4ypGQ3Cgklp17jMwYS+5M9JSTKA1iVeJ3i3lXmMiAQDsTiNxidQ1ddVNUVVU+Li4krvNsYYUw3+TAQLgM4i0l5EQoFrgRmljpkB3OB9fg0w29oHjDGmZvmtashb538X8BVO99G3VHWFiDwGpKrqDOBN4D0RWQ/sw0kWxhhjapBf2whU9Qvgi1Lb/qvE81xgpD9jMMYYUz6buNwYYwKcJQJjjAlwlgiMMSbAWSIwxpgAV+emoRaRTGBLFU9vio1aLsm+jxPZ93GcfRcnqg/fR1tVLXMgVp1LBNUhIqmnmo87ENn3cSL7Po6z7+JE9f37sKohY4wJcJYIjDEmwAVaInjd7QBqGfs+TmTfx3H2XZyoXn8fAdVGYIwx5mSBViIwxhhTiiUCY4wJcAGTCERkmIisEZH1IvKw2/G4SURai8gcEVkpIitE5B63Y3KbiHhEZLGIfOZ2LG4TkYYiMl1EVovIKhE5y+2Y3CIi93n/jSwXkQ9EJNztmPwhIBKBiHiAl4BLgERgjIgkuhuVqwqB+1U1ERgA3Bng3wfAPcAqt4OoJf4OzFTVbkAvAvR7EZFWwN1Aiqom4UynXy+nyg+IRAD0B9ar6kZVzQemAMNdjsk1qrpDVRd5nx/E+Yfeyt2o3CMiCcBlwBtux+I2EYkFBuGsFYKq5qvqAVeDclcwEOFdQTES2O5yPH4RKImgFbCtxOt0AvjGV5KItAP6AL+4HIqbngMeBIpdjqM2aA9kAm97q8reEJEGbgflBlXNAP4GbAV2AFmqOsvdqPwjUBKBKYOIRAEfAveqarbb8bhBRC4HdqvqQrdjqSWCgb7AK6raBzgMBGSbmog0wqk5aA+0BBqIyFh3o/KPQEkEGUDrEq8TvNsCloiE4CSByar6kdvxuOgc4AoR2YxTZThURN53NyRXpQPpqnq0hDgdJzEEoguATaqaqaoFwEfA2S7H5BeBkggWAJ1FpL2IhOI0+MxwOSbXiIjg1AGvUtVn3I7HTar6B1VNUNV2OP9fzFbVevmrryJUdSewTUS6ejedD6x0MSQ3bQUGiEik99/M+dTThnO/rllcW6hqoYjcBXyF0/L/lqqucDksN50DjAOWiUiad9v/864xbcwkYLL3R9NG4CaX43GFqv4iItOBRTg97RZTT6easCkmjDEmwAVK1ZAxxphTsERgjDEBzhKBMcYEOEsExhgT4CwRGGNMgLNEYIyXiBSJSFqJh89G1IpIOxFZ7qvrGeNLATGOwJgKOqKqvd0OwpiaZiUCY05DRDaLyFMiskxEfhWRTt7t7URktogsFZFvRaSNd3u8iHwsIku8j6PTEnhE5B/e+e1niUiE9/i7vWtDLBWRKS59TBPALBEYc1xEqaqh0SX2ZalqMvAizmylAC8A/1TVnsBk4Hnv9ueB71W1F848PUdHsXcGXlLVHsABYIR3+8NAH+91bvfPRzPm1GxksTFeInJIVaPK2L4ZGKqqG72T9e1U1SYisgdooaoF3u07VLWpiGQCCaqaV+Ia7YCvVbWz9/VDQIiqPi4iM4FDwCfAJ6p6yM8f1ZgTWInAmIrRUzyvjLwSz4s43kZ3Gc4Ken2BBd5FUIypMZYIjKmY0SX+/ux9/hPHly68HvjB+/xb4A44thZy7KkuKiJBQGtVnQM8BMQCJ5VKjPEn++VhzHERJWZjBWfd3qNdSBuJyFKcX/VjvNsm4azk9QDOql5HZ+m8B3hdRG7G+eV/B84KV2XxAO97k4UAzwf40pDGBdZGYMxpeNsIUlR1j9uxGOMPVjVkjDEBzkoExhgT4KxEYIwxAc4SgTHGBDhLBMYYE+AsERhjTICzRGCMMQHu/wNIKPvncXhJGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
